{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.cmv\n",
    "posts_collection = db.posts\n",
    "tl_comments_collection = db.tl_comments\n",
    "deltad_replies_collection = db.deltad_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMV:\n",
    "    def __init__(self, doc_type='comment', topic_model='pytextrank', classification_model='xgboost', random_state):\n",
    "        client = MongoClient()\n",
    "        db = client.cmv\n",
    "        self.posts_collection = db.posts\n",
    "        self.tl_comments_collection = db.tl_comments\n",
    "        self.deltad_replies_collection = db.deltad_replies\n",
    "        \n",
    "        self.topic_model=topic_model\n",
    "        \n",
    "        self.deltad_docs = []\n",
    "        self.undeltad_docs = []\n",
    "        self.test_docs = []\n",
    "        self.train_docs = []\n",
    "        \n",
    "        self.train_ids = []\n",
    "        self.train_texts = []\n",
    "        self.train_labels = []\n",
    "        self.test_ids = []\n",
    "        self.test_texts = []\n",
    "        self.test_labels = []\n",
    "        self.val_ids = []\n",
    "        self.val_texts = []\n",
    "        self.val_labels = []\n",
    "        \n",
    "        self.reduced_train_texts = []\n",
    "        self.reduced_test_texts = []\n",
    "        self.reduced_val_texts = []\n",
    "        \n",
    "        if random_state:\n",
    "            rand_state = random_state\n",
    "        \n",
    "        deltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": True}})\n",
    "        if doctype == 'post':\n",
    "            undeltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": False}})\n",
    "            \n",
    "            #retrieve post id, text and label (1=deltad, 0=undeltad)\n",
    "            self.deltad_docs = [{'id': post[f'{doctype}_id'], 'text': post[f'{doctype}_text'], 'label': 1} for post in deltad_post_gen]\n",
    "            self.undeltad_docs = [{'id': post[f'{doctype}_id'], 'text': post[f'{doctype}_text'], 'label': 0} for post in undeltad_post_gen]\n",
    "            \n",
    "        if doctype == 'comment':\n",
    "            # get ids of Top Level Comments that resulted in deltas AND list of all TL Comment IDs for posts where some delta was awarded by OP\n",
    "            post_comment_ids = [(post['tl_comment_delta_parents'], post['comment_ids']) for post in deltad_post_gen]\n",
    "            (deltad_tl_comment_ids, all_tl_comment_ids) = zip(*post_comment_ids)\n",
    "\n",
    "            # flatten lists of lists\n",
    "            deltad_tl_comment_ids = [item for sublist in deltad_tl_comment_ids for item in sublist]\n",
    "            all_tl_comment_ids = [item for sublist in all_tl_comment_ids for item in sublist]\n",
    "\n",
    "            # get ids of TL Comments that did not result in deltas from posts where OP did award deltas\n",
    "            undeltad_tl_comment_ids = list(set(all_tl_comment_ids) - set(deltad_tl_comment_ids))\n",
    "\n",
    "            # if I reimport: deltad_tl_comment_gen = tl_comments_collection.find( {'comment_id': {\"$in\": deltad_tl_comment_ids}})\n",
    "            deltad_tl_comment_gen = tl_comments_collection.find( {'$and': [{'comment_id': {\"$in\": deltad_tl_comment_ids}},{'comment_text': {\"$ne\": '[deleted]'}}]})\n",
    "            # retrieve TL comments NOT resulting in deltas\n",
    "            undeltad_tl_comment_gen = tl_comments_collection.find( {'$and': [{'comment_id': {\"$in\": undeltad_tl_comment_ids}},{'comment_text': {\"$ne\": '[deleted]'}}]})\n",
    "            \n",
    "            #retrieve comment id, text and label (1=deltad, 0=undeltad)\n",
    "            self.deltad_docs = [{'id': comment[f'{doctype}_id'], 'text': comment[f'{doctype}_text'], 'label': 1} for comment in deltad_tl_comment_gen]\n",
    "            self.undeltad_docs = [{'id': comment[f'{doctype}_id'], 'text': comment[f'{doctype}_text'], 'label': 0} for comment in undeltad_tl_comment_gen]\n",
    "\n",
    "    def test_split(self, test_ratio=0.2, val_set=True, val_ratio=0.2):\n",
    "        if val_set = True:\n",
    "            total_ratio = test_ratio + val_ratio\n",
    "            \n",
    "            val_split_d = int(val_ratio*len(self.deltad_docs))\n",
    "            val_split_u = int(val_ratio*len(self.undeltad_docs))\n",
    "            \n",
    "            np.random.seed(seed=rand_state)\n",
    "            np.random.shuffle(self.deltad_docs)\n",
    "            np.random.shuffle(self.undeltad_docs)\n",
    "\n",
    "            self.val_docs = self.deltad_docs[0:val_split_d]\n",
    "            self.val_docs.extend(self.undeltad_docs[0:val_split_u])\n",
    "            \n",
    "            test_split_d = int(total_ratio*len(self.deltad_docs))\n",
    "            test_split_u = int(total_ratio*len(self.undeltad_docs))\n",
    "            \n",
    "            self.test_docs = deltad_docs[val_split_d:test_split_d]\n",
    "            self.test_docs.extend(undeltad_docs[val_split_u:test_split_u])\n",
    "\n",
    "            self.train_docs= self.deltad_docs[test_split_d::]\n",
    "            self.train_docs.extend(self.undeltad_docs[test_split_u::])\n",
    "            \n",
    "            val_tuples = [(doc['id'],doc['text'],doc['label']) for doc in self.val_docs]\n",
    "\n",
    "            (self.val_ids, self.val_texts, self.val_labels) = zip(*val_tuples)\n",
    "            train_tuples = [(doc['id'],doc['text'],doc['label']) for doc in self.train_docs]\n",
    "            test_tuples = [(doc['id'],doc['text'],doc['label']) for doc in self.test_docs]\n",
    "\n",
    "            (self.train_ids, self.train_texts, self.train_labels) = zip(*train_tuples)\n",
    "            (self.test_ids, self.test_texts, self.test_labels) = zip(*test_tuples)\n",
    "            \n",
    "            return self.train_docs, self.val_docs, self.test_docs\n",
    "\n",
    "        else:\n",
    "            test_split_d = int(test_ratio*len(self.deltad_docs))\n",
    "            test_split_u = int(test_ratio*len(self.undeltad_docs))\n",
    "\n",
    "            np.random.seed(seed=rand_state)\n",
    "            np.random.shuffle(self.deltad_docs)\n",
    "            np.random.shuffle(self.undeltad_docs)\n",
    "\n",
    "            self.test_docs = self.deltad_docs[0:test_split_d]\n",
    "            self.test_docs.extend(self.undeltad_docs[0:test_split_u])\n",
    "\n",
    "            self.train_docs= self.deltad_docs[test_split_d::]\n",
    "            self.train_docs.extend(self.undeltad_docs[test_split_u::])\n",
    "\n",
    "            train_tuples = [(doc['id'],doc['text'],doc['label']) for doc in self.train_docs]\n",
    "            test_tuples = [(doc['id'],doc['text'],doc['label']) for doc in self.test_docs]\n",
    "\n",
    "            (self.train_ids, self.train_texts, self.train_labels) = zip(*train_tuples)\n",
    "            (self.test_ids, self.test_texts, self.test_labels) = zip(*test_tuples)\n",
    "\n",
    "            return self.train_docs, self.test_docs\n",
    "\n",
    "    def clean_text(something):\n",
    "        #do something\n",
    "        \n",
    "    def topic_extraction(topic_model):\n",
    "        if topic_model:\n",
    "            use_model = topic_model\n",
    "        else:\n",
    "            use_model = self.topic_model\n",
    "            \n",
    "        if use_model == 'lda':\n",
    "            #do something\n",
    "        elif use_model == 'lsa':\n",
    "            #do something\n",
    "        elif use_model == 'pytextrank':\n",
    "            #do something\n",
    "            \n",
    "        return something\n",
    "    \n",
    "        #self.reduced_train_texts = []\n",
    "        #self.reduced_test_texts = []\n",
    "        #self.reduced_val_texts = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
