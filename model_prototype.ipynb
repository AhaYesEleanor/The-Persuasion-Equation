{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.cmv\n",
    "posts_collection = db.posts\n",
    "tl_comments_collection = db.tl_comments\n",
    "deltad_replies_collection = db.deltad_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the set of texts to use (ie posts vs comments)\n",
    "doctype = 'comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting posts with (or without) deltas awarded\n",
    "deltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": True}})\n",
    "if doctype == 'post':\n",
    "    undeltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doctype == 'comment':\n",
    "    # get ids of Top Level Comments that resulted in deltas AND list of all TL Comment IDs for posts where some delta was awarded by OP\n",
    "    post_comment_ids = [(post['tl_comment_delta_parents'], post['comment_ids']) for post in deltad_post_gen]\n",
    "    (deltad_tl_comment_ids, all_tl_comment_ids) = zip(*post_comment_ids)\n",
    "\n",
    "    # flatten lists of lists\n",
    "    deltad_tl_comment_ids = [item for sublist in deltad_tl_comment_ids for item in sublist]\n",
    "    all_tl_comment_ids = [item for sublist in all_tl_comment_ids for item in sublist]\n",
    "\n",
    "    # get ids of TL Comments that did not result in deltas from posts where OP did award deltas\n",
    "    undeltad_tl_comment_ids = list(set(all_tl_comment_ids) - set(deltad_tl_comment_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doctype == 'comment':\n",
    "    # retrieve TL comments resulting in deltas by id\n",
    "    # if I reimport: deltad_tl_comment_gen = tl_comments_collection.find( {'comment_id': {\"$in\": deltad_tl_comment_ids}})\n",
    "    deltad_tl_comment_gen = tl_comments_collection.find( {'$and': [{'comment_id': {\"$in\": deltad_tl_comment_ids}},{'comment_text': {\"$ne\": '[deleted]'}}]})\n",
    "    # retrieve TL comments NOT resulting in deltas\n",
    "    undeltad_tl_comment_gen = tl_comments_collection.find( {'$and': [{'comment_id': {\"$in\": undeltad_tl_comment_ids}},{'comment_text': {\"$ne\": '[deleted]'}}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the set of texts to use (ie posts vs comments)\n",
    "if doctype == 'comment':\n",
    "    deltad_docs = [{'id': comment[f'{doctype}_id'], 'text': comment[f'{doctype}_text'], 'label': 1} for comment in deltad_tl_comment_gen]\n",
    "    undeltad_docs = [{'id': comment[f'{doctype}_id'], 'text': comment[f'{doctype}_text'], 'label': 0} for comment in undeltad_tl_comment_gen]\n",
    "    \n",
    "elif doctype == 'post':\n",
    "    deltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": True}})\n",
    "    undeltad_post_gen = posts_collection.find( {'tl_comment_delta_parents': {\"$exists\": False}})\n",
    "    \n",
    "    deltad_docs = [{'id': post[f'{doctype}_id'], 'text': post[f'{doctype}_text'], 'label': 1} for post in deltad_post_gen]\n",
    "    undeltad_docs = [{'id': post[f'{doctype}_id'], 'text': post[f'{doctype}_text'], 'label': 0} for post in undeltad_post_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "test_split_d = int(0.2*len(deltad_docs))\n",
    "test_split_u = int(0.2*len(undeltad_docs))\n",
    "\n",
    "np.random.seed(seed=rand_state)\n",
    "np.random.shuffle(deltad_docs)\n",
    "np.random.shuffle(undeltad_docs)\n",
    "\n",
    "test_docs = deltad_docs[0:test_split_d]\n",
    "test_docs.extend(undeltad_docs[0:test_split_u])\n",
    "\n",
    "train_docs= deltad_docs[test_split_d::]\n",
    "train_docs.extend(undeltad_docs[test_split_u::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuples = [(doc['id'],doc['text'],doc['label']) for doc in train_docs]\n",
    "test_tuples = [(doc['id'],doc['text'],doc['label']) for doc in test_docs]\n",
    "\n",
    "#train_docs = []\n",
    "#test_docs = []\n",
    "\n",
    "(train_ids, train_texts, train_labels) = zip(*train_tuples)\n",
    "(test_ids, test_texts, test_labels) = zip(*test_tuples)\n",
    "\n",
    "train_tuples = []\n",
    "test_tuples = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(texts, tokenizer, stemmer):\n",
    "    stemmer_inst = stemmer()\n",
    "    tokenizer_inst = tokenizer()\n",
    "    cleaned_texts = []\n",
    "    for text in texts:\n",
    "        #cleaned_words = []\n",
    "        \n",
    "        #strip punctuation and digits from whole post\n",
    "        to_replace = [punc for punc in string.punctuation+string.digits if punc!=\"'\"]\n",
    "        translate_dict = {key: ' ' for key in to_replace}\n",
    "        translate_dict[\"'\"] = ''\n",
    "        replacement_table = str.maketrans(translate_dict)\n",
    "        stripped_text = text.translate(replacement_table)\n",
    "        \n",
    "        #lower case post\n",
    "        lowered_text = stripped_text.lower()\n",
    "        cleaned_texts.append(lowered_text)\n",
    "        #tokenized_post = tokenizer_inst.tokenize(stripped_post) \n",
    "        #for word in tokenized_post:\n",
    "            #low_word = stemmer_inst.stem(word.lower())\n",
    "            #cleaned_words.append(low_word)\n",
    "            #remove stopwords?\n",
    "            #if low_word not in stopwords:\n",
    "            #    cleaned_words.append(low_word)\n",
    "        # cleaned_posts.append(' '.join(cleaned_words))\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer\n",
    "tokenizer = WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_texts = clean_text(train_texts, tokenizer, stemmer)\n",
    "cleaned_test_texts = clean_text(test_texts, tokenizer, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an organ donor.  I want my organs to go to people who need my organs. I do not want my donation of my organs to get involved in notion of social justice, of \"deserving\" and so on.  The organ I donate goes to someone who is sick, because being sick is a really shitty thing.  It's not _less shitty_ when it happens to an asshole, or even to someone who doesn't want to donate their own organs.  My gift is not contingent.\n",
      "\n",
      "I agree with you that it should not be taken for granted, I believe that it should be wildly promoted and that we should change our systems of becoming an organ donor.  As you note, this is about saving lives.  I believe it to be bad to create a system that implicitly values one life greater than the other, and that is what your proposal does.  It says that you deserve to live because you are an organ donor and you don't because you aren't.\n",
      "\n",
      "And...Get your shit together Canada!\n",
      "i am an organ donor   i want my organs to go to people who need my organs  i do not want my donation of my organs to get involved in notion of social justice  of  deserving  and so on   the organ i donate goes to someone who is sick  because being sick is a really shitty thing   its not  less shitty  when it happens to an asshole  or even to someone who doesnt want to donate their own organs   my gift is not contingent \n",
      "\n",
      "i agree with you that it should not be taken for granted  i believe that it should be wildly promoted and that we should change our systems of becoming an organ donor   as you note  this is about saving lives   i believe it to be bad to create a system that implicitly values one life greater than the other  and that is what your proposal does   it says that you deserve to live because you are an organ donor and you dont because you arent \n",
      "\n",
      "and   get your shit together canada \n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])\n",
    "print(cleaned_train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "my_vectorizer = CountVectorizer(max_df=0.85, min_df=25,\n",
    "                                max_features=1000,\n",
    "                                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train_texts = my_vectorizer.fit_transform(cleaned_train_texts)\n",
    "vectorized_test_texts = my_vectorizer.transform(cleaned_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cv = pd.DataFrame(vectorized_train_texts.toarray(), columns=my_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_model = TruncatedSVD(n_components=100, random_state=rand_state)\n",
    "lsa_model.fit(vectorized_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_train_texts = lsa_model.transform(vectorized_train_texts)\n",
    "lsa_test_texts = lsa_model.transform(vectorized_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "peoples, key, driving, life, thing, majority, ways, wanted, theyve, thousands, reality, imagine, saying, knowledge, gone, doing, th, youve, going, personal\n",
      "\n",
      "Topic  1\n",
      "peoples, books, win, general, trade, quite, gender, greater, questions, complex, ignore, policies, sound, race, hate, data, identity, popular, currently, safety\n",
      "\n",
      "Topic  2\n",
      "got, money, truly, voted, wages, mind, talking, paying, majority, creating, stop, increasing, taught, workers, effect, status, pass, commit, save, powerful\n",
      "\n",
      "Topic  3\n",
      "truly, voted, driving, commit, life, hes, hillary, pass, thing, president, car, politicians, save, entire, vs, republican, imagine, republicans, deserve, drive\n",
      "\n",
      "Topic  4\n",
      "life, games, key, gay, play, peoples, thousands, assuming, playing, plenty, congress, gone, view, players, taxes, new, future, money, theyll, workers\n",
      "\n",
      "Topic  5\n",
      "general, wont, key, meet, trade, wages, mind, money, life, got, talking, womens, share, ignore, room, making, paying, workers, field, increasing\n",
      "\n",
      "Topic  6\n",
      "books, win, key, life, quite, citizens, truly, liberal, data, apply, current, policies, stop, yes, race, powerful, answer, thousands, difference, approach\n",
      "\n",
      "Topic  7\n",
      "driving, books, key, win, knowledge, youve, wanted, wages, mind, got, quite, policies, needed, imagine, data, paying, science, federal, talking, apply\n",
      "\n",
      "Topic  8\n",
      "books, thing, games, win, gay, money, wont, meet, wages, play, mind, data, paying, quite, playing, plenty, talking, apply, truly, congress\n",
      "\n",
      "Topic  9\n",
      "life, driving, got, general, assuming, theyve, ways, workers, protect, books, female, data, study, racist, use, guess, risk, win, knowledge, correct\n",
      "\n",
      "Topic  10\n",
      "got, games, gay, rights, play, thing, status, stop, friend, laws, risk, felt, books, ways, use, spent, sort, lead, direct, congress\n",
      "\n",
      "Topic  11\n",
      "driving, citizens, games, wanted, gay, voted, play, thousands, books, city, general, supply, particular, feeling, pass, plenty, having, needed, vs, case\n",
      "\n",
      "Topic  12\n",
      "citizens, wont, got, meet, life, key, city, thing, risk, supply, feeling, particular, rights, laws, left, gay, wanted, felt, peoples, lead\n",
      "\n",
      "Topic  13\n",
      "wont, meet, thousands, worse, theyve, yes, study, majority, human, racist, biological, knowledge, needed, science, election, studies, relatively, wars, liberal, humans\n",
      "\n",
      "Topic  14\n",
      "personal, majority, friend, wont, money, meet, wanted, gone, truly, saying, doesnt, spent, rights, moral, hate, basic, racist, doing, youve, games\n",
      "\n",
      "Topic  15\n",
      "liberal, driving, human, wages, mind, general, key, moral, humans, doesnt, areas, truly, abortion, books, gay, rights, win, doing, assuming, meant\n",
      "\n",
      "Topic  16\n",
      "liberal, wanted, money, got, rights, going, imagine, youve, truly, th, live, needed, wont, thing, guess, abortion, hes, human, female, general\n",
      "\n",
      "Topic  17\n",
      "personal, got, workers, thing, liberal, thousands, majority, wont, wanted, voted, driving, stop, key, meet, life, status, love, doesnt, trade, correct\n",
      "\n",
      "Topic  18\n",
      "majority, truly, friend, got, hes, driving, general, knowledge, gone, money, doing, wars, basic, apply, understand, doesnt, spent, reality, protect, difference\n",
      "\n",
      "Topic  19\n",
      "wages, personal, mind, thousands, imagine, got, truly, knowledge, bernie, guess, hes, wanted, worse, gay, wars, th, want, laws, play, going\n",
      "\n",
      "Topic  20\n",
      "gone, got, ways, workers, biological, liberal, theyve, basic, assuming, love, knowledge, wont, worse, theyre, biggest, youve, reality, saying, pass, direct\n",
      "\n",
      "Topic  21\n",
      "liberal, money, personal, study, election, gay, science, friend, community, college, truly, paying, key, saying, games, studies, direct, bernie, rights, imagine\n",
      "\n",
      "Topic  22\n",
      "imagine, going, needed, th, guess, stop, youve, status, driving, private, personal, human, meant, meet, areas, laws, gun, games, powerful, points\n",
      "\n",
      "Topic  23\n",
      "gone, study, science, election, liberal, community, general, studies, rights, biological, imagine, voted, college, protect, scientific, university, majority, come, basic, high\n",
      "\n",
      "Topic  24\n",
      "assuming, workers, got, thousands, liberal, youve, rights, doing, imagine, meet, knowledge, wont, voted, majority, peoples, saying, issues, correct, spent, years\n",
      "\n",
      "Topic  25\n",
      "wanted, youve, majority, truly, liberal, study, wages, mind, racist, gay, doing, workers, thing, studies, knowledge, science, university, ways, college, assuming\n",
      "\n",
      "Topic  26\n",
      "imagine, majority, workers, theyve, saying, meant, needed, forcing, assuming, areas, got, supposed, case, points, biological, gay, reality, mind, thing, healthcare\n",
      "\n",
      "Topic  27\n",
      "ways, wanted, gone, bernie, racist, imagine, female, majority, saying, points, relatively, general, views, love, powerful, biggest, creating, moral, wars, money\n",
      "\n",
      "Topic  28\n",
      "relatively, bernie, assuming, imagine, saying, character, religious, got, youve, powerful, wanted, money, majority, politicians, views, advantage, yes, god, direct, points\n",
      "\n",
      "Topic  29\n",
      "assuming, friend, workers, sound, wanted, gone, worse, guess, stop, yes, doing, minorities, years, status, going, spent, needed, laws, saying, fact\n",
      "\n",
      "Topic  30\n",
      "liberal, assuming, ways, reality, knowledge, imagine, majority, worse, theyve, powerful, status, laws, female, guess, bernie, stop, difference, wages, mind, relatively\n",
      "\n",
      "Topic  31\n",
      "friend, doing, ways, thousands, imagine, doesnt, youve, meant, maybe, th, status, stop, spent, female, love, felt, areas, extent, laws, sound\n",
      "\n",
      "Topic  32\n",
      "youve, theyve, ways, needed, majority, bernie, thousands, gay, imagine, key, truly, sound, workers, particular, driving, rights, female, kill, personal, assuming\n",
      "\n",
      "Topic  33\n",
      "assuming, theyve, racist, laws, doesnt, guess, money, basic, gone, thousands, study, advantage, university, lot, points, causes, views, theory, th, use\n",
      "\n",
      "Topic  34\n",
      "knowledge, rights, direct, stop, imagine, doing, wanted, status, doesnt, money, workers, worse, relatively, laws, love, felt, areas, moral, meant, advantage\n",
      "\n",
      "Topic  35\n",
      "saying, knowledge, gone, status, laws, stop, voted, theyve, felt, difference, th, gay, moral, racist, basic, let, money, meant, thousands, meet\n",
      "\n",
      "Topic  36\n",
      "yes, powerful, saying, workers, direct, liberal, stop, driving, status, lot, hate, felt, ways, win, love, laws, human, rights, play, congress\n",
      "\n",
      "Topic  37\n",
      "knowledge, friend, use, workers, points, direct, needed, character, views, guess, gone, money, liberal, truly, yes, issues, human, feeling, knows, ask\n",
      "\n",
      "Topic  38\n",
      "direct, relatively, needed, saying, guess, bernie, reality, love, thousands, religious, gun, voted, workers, liberal, use, helps, city, doing, god, stop\n",
      "\n",
      "Topic  39\n",
      "direct, doesnt, lot, youve, assuming, needed, got, college, saying, sort, thousands, human, talking, imagine, love, liberal, questions, new, majority, powerful\n",
      "\n",
      "Topic  40\n",
      "powerful, needed, doing, nuclear, issues, thousands, college, points, money, liberal, study, status, win, way, life, private, equality, safety, maybe, truly\n",
      "\n",
      "Topic  41\n",
      "doing, th, character, direct, creating, guess, maybe, points, needed, theyre, data, wanted, gun, race, going, majority, gay, private, gone, pass\n",
      "\n",
      "Topic  42\n",
      "points, th, sound, stop, reality, lot, workers, talking, moral, laws, direct, status, relatively, ways, majority, increasing, theory, forcing, thousands, going\n",
      "\n",
      "Topic  43\n",
      "sound, th, human, voted, private, sort, direct, powerful, imagine, gone, humans, assuming, going, thousands, risk, realize, issues, alternative, feeling, questions\n",
      "\n",
      "Topic  44\n",
      "sound, reality, needed, sort, female, character, youve, money, private, saying, racist, laws, knowledge, marriage, data, status, stop, gay, pass, lot\n",
      "\n",
      "Topic  45\n",
      "talking, sound, doing, sort, love, human, increasing, paying, taught, guess, use, marriage, knowledge, years, going, protect, risk, gone, city, yes\n",
      "\n",
      "Topic  46\n",
      "needed, yes, relatively, gone, issues, got, meant, assuming, study, feeling, going, personal, areas, citizens, college, forcing, theyve, religious, doing, spent\n",
      "\n",
      "Topic  47\n",
      "love, sound, points, city, direct, doesnt, powerful, money, yes, got, going, assuming, kill, mind, wages, particular, science, truly, look, nuclear\n",
      "\n",
      "Topic  48\n",
      "love, racist, voted, workers, gay, needed, yes, reality, human, worse, use, new, youve, points, data, bernie, talking, theyve, doesnt, friend\n",
      "\n",
      "Topic  49\n",
      "going, love, pass, worse, theyve, college, wars, supply, study, workers, games, creating, moral, politicians, play, risk, parts, lets, congress, points\n",
      "\n",
      "Topic  50\n",
      "issues, private, relatively, love, data, creating, ive, worse, wars, created, doesnt, hate, politicians, thousands, youve, female, gender, issue, left, knowledge\n",
      "\n",
      "Topic  51\n",
      "human, money, gay, guess, reality, stop, love, character, alternative, science, wars, city, politicians, gun, risk, points, th, spent, status, relatively\n",
      "\n",
      "Topic  52\n",
      "direct, moral, guess, worse, reality, powerful, nuclear, meant, win, gone, politicians, use, doing, areas, youve, gun, gay, study, racist, spent\n",
      "\n",
      "Topic  53\n",
      "th, needed, yes, moral, biological, sound, doesnt, points, games, reality, issues, worse, love, character, college, hate, super, playing, ask, meaning\n",
      "\n",
      "Topic  54\n",
      "th, pass, politicians, use, relatively, spent, parts, hate, supply, meant, forcing, workers, areas, used, talking, experiences, knowledge, long, majority, economy\n",
      "\n",
      "Topic  55\n",
      "issues, love, talking, th, paying, biological, rights, needed, increasing, taught, bernie, advantage, assuming, direct, dollars, human, laws, majority, thousands, theyve\n",
      "\n",
      "Topic  56\n",
      "character, lot, love, relatively, doesnt, meant, advantage, gay, powerful, forcing, nuclear, areas, views, liberal, college, th, religious, economy, citizens, feeling\n",
      "\n",
      "Topic  57\n",
      "moral, private, going, saying, particular, character, city, doesnt, hes, pass, advantage, read, issues, difference, kill, saw, human, games, morality, trade\n",
      "\n",
      "Topic  58\n",
      "assuming, private, knowledge, games, congress, data, supply, play, friend, direct, powerful, stop, relatively, talking, complex, doesnt, reality, playing, science, theyve\n",
      "\n",
      "Topic  59\n",
      "worse, private, sort, spent, advantage, voted, hate, status, love, bernie, points, views, lot, congress, use, theory, probably, play, understand, risk\n",
      "\n",
      "Topic  60\n",
      "moral, lot, love, going, assuming, stop, biological, needed, wars, use, demand, theory, female, theyre, th, having, gender, morality, experiences, friend\n",
      "\n",
      "Topic  61\n",
      "racist, character, use, worse, relatively, th, needed, going, data, new, theory, city, biological, human, workers, money, tried, female, gender, religious\n",
      "\n",
      "Topic  62\n",
      "use, wars, sound, love, character, college, advantage, like, ask, rights, study, apply, money, man, meant, used, creating, knowledge, using, basic\n",
      "\n",
      "Topic  63\n",
      "books, apply, wars, trade, issues, protect, friend, saying, th, female, theyll, love, advantage, realize, direct, theory, points, gender, doing, understand\n",
      "\n",
      "Topic  64\n",
      "advantage, moral, biological, racist, direct, data, talking, love, hes, going, ways, meet, theyre, relatively, doing, case, books, marriage, experiences, protect\n",
      "\n",
      "Topic  65\n",
      "wars, spent, laws, difference, hate, needed, basic, moral, like, voted, workers, dont, views, differences, love, experiences, particular, creating, current, human\n",
      "\n",
      "Topic  66\n",
      "creating, theyre, advantage, city, issues, risk, apply, racist, powerful, data, theory, personal, games, knowledge, particular, forcing, ways, impossible, guess, case\n",
      "\n",
      "Topic  67\n",
      "theyre, basic, college, look, dollars, hes, yeah, status, dont, sort, yes, donald, community, case, voted, male, female, friend, theyll, good\n",
      "\n",
      "Topic  68\n",
      "female, new, theyre, basic, protect, creating, dollars, doing, moral, election, citizens, wont, bernie, scientific, nuclear, paying, games, prices, science, having\n",
      "\n",
      "Topic  69\n",
      "worse, lot, supply, issues, protect, bernie, love, moral, science, case, election, lead, th, sort, laws, scientific, doesnt, trade, prices, use\n",
      "\n",
      "Topic  70\n",
      "new, laws, marriage, theyre, theory, direct, gender, man, realize, private, theyll, left, books, supply, yes, moral, bernie, spent, risk, hate\n",
      "\n",
      "Topic  71\n",
      "new, hes, protect, experiences, apply, meat, stop, sort, politicians, dollars, arguments, needed, movie, spent, views, violence, allows, political, doesnt, look\n",
      "\n",
      "Topic  72\n",
      "theyre, theory, worse, pass, meat, president, win, protect, yes, basic, value, love, friend, says, biggest, experiences, safety, private, laws, depending\n",
      "\n",
      "Topic  73\n",
      "female, trade, advantage, gender, creating, race, going, risk, direct, points, protect, questions, quite, marriage, hate, human, womens, win, case, gone\n",
      "\n",
      "Topic  74\n",
      "basic, lot, marriage, sound, study, gender, win, moral, dollars, studies, save, biggest, knowledge, private, theory, look, character, supply, theyll, realize\n",
      "\n",
      "Topic  75\n",
      "hes, president, use, creating, yes, trade, male, views, lead, womens, biggest, share, spent, city, live, direct, judge, friends, experiences, love\n",
      "\n",
      "Topic  76\n",
      "politicians, like, female, realize, hate, forcing, case, theory, hes, meat, spent, gone, status, doesnt, win, yes, judge, stop, man, exist\n",
      "\n",
      "Topic  77\n",
      "theyre, bernie, talking, male, wars, ask, doesnt, having, politicians, theyll, city, like, spent, needed, areas, play, middle, books, share, meant\n",
      "\n",
      "Topic  78\n",
      "trade, experiences, causes, male, look, theyre, womens, meant, sanders, laws, college, politicians, love, biological, value, make, race, tried, insurance, exist\n",
      "\n",
      "Topic  79\n",
      "job, data, politicians, yes, ive, basic, make, like, way, wont, race, meaning, safety, study, paying, claim, court, debt, particular, stop\n",
      "\n",
      "Topic  80\n",
      "theory, views, trade, theyll, politicians, difference, sound, human, case, way, claim, college, womens, biological, movie, race, spent, meat, sort, allows\n",
      "\n",
      "Topic  81\n",
      "theyre, sound, political, hate, apply, use, difference, new, president, data, biggest, theory, female, private, gender, spent, friends, experiences, race, case\n",
      "\n",
      "Topic  82\n",
      "wars, new, views, case, supply, worse, marriage, demand, win, ask, relatively, theyre, fact, quite, powerful, paying, friend, private, workers, makes\n",
      "\n",
      "Topic  83\n",
      "risk, theyre, case, difference, stop, ask, lot, issues, politicians, protect, way, direct, forcing, court, healthcare, exist, policies, value, able, study\n",
      "\n",
      "Topic  84\n",
      "ask, experiences, laws, save, tried, dollars, president, live, fact, hes, way, job, man, safety, case, donald, understand, community, opinion, th\n",
      "\n",
      "Topic  85\n",
      "basic, ask, share, ideas, apply, realize, stop, hes, politicians, saw, political, games, differences, worse, abortion, college, says, understand, conversation, meant\n",
      "\n",
      "Topic  86\n",
      "meat, yeah, play, stop, worse, claim, fairly, marriage, bear, advantage, sanders, used, industry, president, causes, hate, gender, fact, th, dont\n",
      "\n",
      "Topic  87\n",
      "play, ask, hate, dollars, apply, like, causes, sort, trade, supply, allows, guess, basic, tried, solution, congress, donald, meet, moral, court\n",
      "\n",
      "Topic  88\n",
      "realize, dollars, live, risk, saw, tried, kill, donald, read, theyre, way, truly, total, politicians, increasing, fairly, solution, long, getting, views\n",
      "\n",
      "Topic  89\n",
      "talking, look, dollars, creating, lead, money, safety, workers, president, helps, donald, supply, allows, wont, politicians, commit, science, laws, causes, apply\n",
      "\n",
      "Topic  90\n",
      "live, race, share, like, difference, years, supply, primary, community, games, matters, sort, causes, case, ask, apply, judge, human, exist, make\n",
      "\n",
      "Topic  91\n",
      "theyll, risk, lead, biggest, industry, protect, helps, matters, hes, like, election, ask, race, case, individuals, fact, right, win, trade, exist\n",
      "\n",
      "Topic  92\n",
      "realize, sort, pass, experiences, nuclear, left, im, points, man, provide, lead, kill, character, creating, meaning, marriage, getting, hes, money, dollars\n",
      "\n",
      "Topic  93\n",
      "judge, ask, community, way, read, male, years, theory, value, ive, data, like, forcing, maintain, biological, creating, games, dont, democracy, new\n",
      "\n",
      "Topic  94\n",
      "yeah, creating, status, dollars, helps, paying, games, gender, super, industry, says, debt, donald, depending, study, make, exactly, pass, felt, way\n",
      "\n",
      "Topic  95\n",
      "trade, save, judge, questions, ideas, president, dont, commit, politicians, able, relatively, like, realize, meaning, leaving, protect, word, private, policies, big\n",
      "\n",
      "Topic  96\n",
      "meaning, claim, marriage, maybe, hes, meat, play, abortion, years, look, yeah, car, female, theory, bear, bernie, movie, dollars, points, decision\n",
      "\n",
      "Topic  97\n",
      "theory, yeah, saw, nuclear, supply, judge, biggest, hes, just, helps, make, character, fact, areas, having, run, ask, human, save, meat\n",
      "\n",
      "Topic  98\n",
      "look, views, wars, primary, trade, gender, like, theory, make, wont, hes, matters, left, benefits, increasing, super, man, citizens, companies, depending\n",
      "\n",
      "Topic  99\n",
      "biggest, politicians, super, questions, nuclear, college, marriage, meet, race, dont, protect, look, way, value, leaving, risk, causes, demand, poor, status\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_model,my_vectorizer.get_feature_names(),20) # We have to look at the topics before hand and then add the labels afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 150\n",
    "n_iter = 13\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                max_iter=n_iter,\n",
    "                                random_state=rand_state,\n",
    "                               learning_method='online')\n",
    "lda_train_texts = lda_model.fit_transform(vectorized_train_texts)\n",
    "lda_test_texts = lda_model.transform(vectorized_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "real, lives, problems, relationship, long, healthy, global, relationships, term, experiences, thousands, lack, think, way, going, levels, totally, exists, lots, working\n",
      "\n",
      "Topic  1\n",
      "general, actions, argue, experience, certain, given, claim, example, argument, does, way, second, particular, fact, choose, think, define, role, present, generally\n",
      "\n",
      "Topic  2\n",
      "police, individuals, race, single, racist, minority, equally, random, related, exists, certainly, did, capable, personally, just, saying, say, like, comes, people\n",
      "\n",
      "Topic  3\n",
      "thing, debt, national, essentially, university, honestly, lot, takes, choices, policy, systems, mind, legal, high, havent, question, goes, elected, vote, solution\n",
      "\n",
      "Topic  4\n",
      "like, great, just, im, kind, lot, guy, friends, think, really, pretty, didnt, got, stuff, sure, know, thats, follow, shit, little\n",
      "\n",
      "Topic  5\n",
      "state, issue, illegal, eu, impossible, federal, deal, consent, essentially, totally, laws, isnt, allowing, want, happen, completely, used, nation, situation, just\n",
      "\n",
      "Topic  6\n",
      "live, reasonable, liberal, responsibility, identify, primary, technology, lets, edit, wage, longer, problem, dangerous, fit, acceptable, means, things, positive, provide, apply\n",
      "\n",
      "Topic  7\n",
      "doing, help, did, needs, ask, tell, way, questions, job, whats, better, asking, people, problem, thing, attention, career, didnt, happening, instead\n",
      "\n",
      "Topic  8\n",
      "different, personal, countries, reasons, hard, living, language, easier, easy, difficult, conditions, standards, outside, makes, scenario, better, work, time, reason, ultimately\n",
      "\n",
      "Topic  9\n",
      "thousands, belief, theyre, choices, fun, shouldnt, play, access, individuals, men, did, easily, factors, actions, happen, home, exactly, parents, false, extremely\n",
      "\n",
      "Topic  10\n",
      "yes, terms, building, happens, positive, depends, total, short, tldr, instead, certainly, hold, explain, time, natural, thing, youve, think, really, massive\n",
      "\n",
      "Topic  11\n",
      "deleted, entirely, required, sort, sexual, candidates, away, humans, continue, including, left, brain, ways, wont, defense, help, moral, liberal, voters, old\n",
      "\n",
      "Topic  12\n",
      "public, opinion, court, reason, include, likely, talk, said, regardless, potential, lot, sure, group, case, agree, wrong, wants, doesnt, term, parties\n",
      "\n",
      "Topic  13\n",
      "basically, long, op, punishment, change, trump, truth, pain, nearly, watch, rest, assume, healthcare, act, require, gets, animals, cases, youre, easily\n",
      "\n",
      "Topic  14\n",
      "health, cost, benefits, benefit, costs, healthcare, study, spending, industry, economy, programs, medical, increase, good, provide, education, high, likely, direct, better\n",
      "\n",
      "Topic  15\n",
      "believe, definition, political, term, came, examples, truth, source, specifically, common, sense, agree, reason, extremely, did, make, discussion, groups, says, clear\n",
      "\n",
      "Topic  16\n",
      "black, family, just, white, people, youre, run, going, drugs, need, try, thats, families, life, probably, body, dont, control, hard, make\n",
      "\n",
      "Topic  17\n",
      "action, conclusion, spending, evil, situations, maintain, voters, religious, children, consequences, language, thought, changed, start, emotional, hes, took, facts, scale, stupid\n",
      "\n",
      "Topic  18\n",
      "doesnt, mean, does, just, hate, make, means, allowed, say, thats, tell, want, sense, directly, example, certain, simply, dont, better, large\n",
      "\n",
      "Topic  19\n",
      "times, americans, rational, understand, people, think, like, want, personally, say, thinking, better, disagree, source, health, means, following, public, actual, use\n",
      "\n",
      "Topic  20\n",
      "difference, house, home, property, plan, wealth, moment, living, comes, theres, make, level, time, seeing, taking, fact, act, certain, means, life\n",
      "\n",
      "Topic  21\n",
      "times, totally, lack, moral, place, remember, require, health, access, sort, completely, subject, war, vast, cultural, security, violent, spend, save, group\n",
      "\n",
      "Topic  22\n",
      "humans, species, genetic, just, like, year, problem, far, dont, human, entire, started, doesnt, wrong, theyre, day, environment, wont, days, living\n",
      "\n",
      "Topic  23\n",
      "art, modern, popular, makes, goal, sense, absolute, planet, especially, powerful, interests, perspective, world, complex, happen, really, skill, common, theres, simply\n",
      "\n",
      "Topic  24\n",
      "thought, human, basically, content, teach, population, th, critical, immigration, high, attention, agree, victims, companies, end, harm, despite, theyre, abuse, impossible\n",
      "\n",
      "Topic  25\n",
      "definition, year, effective, vs, highly, decisions, criminal, moment, online, popular, politics, unfair, test, research, relatively, issues, primary, clear, understand, lack\n",
      "\n",
      "Topic  26\n",
      "potential, mentioned, end, cost, word, cars, building, life, men, cases, pain, place, players, obviously, relatively, deleted, europe, birth, forcing, low\n",
      "\n",
      "Topic  27\n",
      "right, social, rights, respect, amendment, liberal, group, important, legal, ones, positions, hold, constitution, groups, force, certain, members, basic, protect, practice\n",
      "\n",
      "Topic  28\n",
      "worth, status, totally, police, term, running, gender, fuck, terrorism, literally, shouldnt, started, hand, evolution, democratic, civil, id, means, opinions, safe\n",
      "\n",
      "Topic  29\n",
      "family, significant, families, home, white, black, important, life, consider, level, honestly, practice, social, willing, poverty, property, certain, american, americans, need\n",
      "\n",
      "Topic  30\n",
      "small, movie, main, larger, stand, movies, relatively, prefer, dogs, entire, little, parts, meaning, given, work, clearly, important, youd, line, options\n",
      "\n",
      "Topic  31\n",
      "wear, god, businesses, took, body, th, theres, majority, effectively, government, posts, limited, lot, children, states, held, ai, average, specifically, necessary\n",
      "\n",
      "Topic  32\n",
      "examples, plenty, society, depends, uk, various, population, mother, example, sexist, say, individual, account, art, goal, pass, levels, factors, false, killing\n",
      "\n",
      "Topic  33\n",
      "giving, car, cars, drive, reddit, driving, online, required, instead, making, shows, like, possible, spend, make, decision, place, self, lot, use\n",
      "\n",
      "Topic  34\n",
      "years, year, old, ago, changed, dog, largely, didnt, couple, significantly, early, today, started, finally, allow, gets, got, compared, given, used\n",
      "\n",
      "Topic  35\n",
      "potentially, treatment, financial, alcohol, use, depends, energy, words, point, factors, computer, form, affect, build, days, popular, guns, gain, completely, aware\n",
      "\n",
      "Topic  36\n",
      "care, law, laws, people, individual, politicians, fully, dont, quality, peoples, abuse, emotional, level, extreme, life, apply, support, impact, problem, just\n",
      "\n",
      "Topic  37\n",
      "heard, doubt, background, supporters, best, respect, gives, better, time, today, arguments, local, exist, relatively, quickly, took, eat, special, effective, day\n",
      "\n",
      "Topic  38\n",
      "wants, response, differences, democrats, benefit, mention, decision, year, future, impossible, individual, defense, present, common, plenty, ultimately, great, price, took, various\n",
      "\n",
      "Topic  39\n",
      "food, living, effort, thousands, perfectly, meat, tried, death, children, act, problems, face, complete, future, teach, particular, separate, difference, local, looking\n",
      "\n",
      "Topic  40\n",
      "perfectly, women, nice, considered, sexist, social, calling, responsible, primary, happens, sound, sexual, entire, building, science, employees, looks, knowledge, short, terms\n",
      "\n",
      "Topic  41\n",
      "religion, religious, middle, beliefs, belief, believe, christian, muslims, islam, santa, religions, people, western, world, strong, dont, different, think, does, history\n",
      "\n",
      "Topic  42\n",
      "lets, business, big, huge, say, wants, start, reality, million, forced, right, want, following, thats, isnt, turn, saying, goes, lose, order\n",
      "\n",
      "Topic  43\n",
      "effect, exactly, drug, half, drugs, murder, ground, trust, exact, worse, reasonable, heres, massive, high, example, rate, work, points, lower, different\n",
      "\n",
      "Topic  44\n",
      "wage, job, jobs, minimum, income, people, buy, money, debt, make, work, rich, economy, labor, pay, market, dollars, inflation, prices, wages\n",
      "\n",
      "Topic  45\n",
      "theory, intelligence, choices, nice, scale, basically, genetic, time, home, water, problem, highly, amendment, public, looking, feminism, looks, businesses, bunch, labor\n",
      "\n",
      "Topic  46\n",
      "society, consider, create, land, created, today, creating, considering, gain, sell, quickly, incredibly, history, modern, idea, past, certainly, people, did, reason\n",
      "\n",
      "Topic  47\n",
      "day, people, end, wont, just, dead, wouldnt, days, time, ones, thats, simply, like, tend, gone, produce, happen, maybe, arent, lots\n",
      "\n",
      "Topic  48\n",
      "trump, hillary, clinton, media, sanders, support, bernie, supporters, think, campaign, trumps, donald, hes, people, president, said, like, candidate, just, voted\n",
      "\n",
      "Topic  49\n",
      "black, white, people, group, racism, groups, racist, race, th, news, hear, issues, fact, matter, isnt, likely, peoples, certain, think, assume\n",
      "\n",
      "Topic  50\n",
      "new, time, idea, behavior, ideas, changing, including, okay, successful, true, original, universe, existence, set, definitely, rest, long, computer, mind, complete\n",
      "\n",
      "Topic  51\n",
      "food, cause, eat, arguments, happy, eating, suffering, morally, causes, reduce, products, argument, health, arguing, reason, directly, prevent, impact, people, does\n",
      "\n",
      "Topic  52\n",
      "women, gender, men, sex, woman, man, trans, sexual, identity, identify, just, people, way, feel, birth, sexist, body, think, opposite, biological\n",
      "\n",
      "Topic  53\n",
      "removed, people, job, significantly, willing, wage, need, income, minimum, work, price, labor, jobs, number, point, source, probably, market, little, power\n",
      "\n",
      "Topic  54\n",
      "great, pretty, kind, mean, ive, doesnt, didnt, obviously, truly, examples, think, say, sure, im, guy, got, win, did, dont, way\n",
      "\n",
      "Topic  55\n",
      "black, white, families, american, america, americans, government, wealth, economic, poverty, important, property, social, today, theres, family, majority, society, consider, housing\n",
      "\n",
      "Topic  56\n",
      "best, decisions, decision, make, democracy, youd, choices, speak, worst, responsible, longer, way, likely, useful, logic, office, making, opposed, things, fact\n",
      "\n",
      "Topic  57\n",
      "ok, probably, looking, million, ads, list, religions, seriously, okay, birth, instead, half, theyre, individual, rules, concept, highly, things, women, company\n",
      "\n",
      "Topic  58\n",
      "requires, things, science, force, posts, drive, children, hope, negative, possible, father, certainly, person, group, op, absolute, figure, set, ago, movement\n",
      "\n",
      "Topic  59\n",
      "degree, better, want, gets, greater, currently, require, option, cut, share, gives, pick, long, likely, options, chance, hands, influence, held, limited\n",
      "\n",
      "Topic  60\n",
      "free, decisions, definition, thought, think, experience, actions, know, argument, using, assumption, make, exist, source, edit, choose, doesnt, second, isnt, say\n",
      "\n",
      "Topic  61\n",
      "child, children, parents, life, abortion, age, mother, kid, birth, having, parent, support, baby, adult, father, young, think, able, biological, make\n",
      "\n",
      "Topic  62\n",
      "free, speech, companies, freedom, company, terrible, considered, ban, people, forcing, want, choose, way, literally, force, makes, allows, hurt, create, reason\n",
      "\n",
      "Topic  63\n",
      "term, turn, mental, obama, week, got, truly, perfectly, animals, places, complex, dollars, ok, hell, investment, parties, voters, affect, star, democracy\n",
      "\n",
      "Topic  64\n",
      "vote, party, voting, president, political, candidate, parties, election, republican, candidates, voters, republicans, democratic, democrats, votes, politics, obama, elected, win, issues\n",
      "\n",
      "Topic  65\n",
      "person, argument, action, persons, judge, specific, logical, common, similar, attack, making, isnt, vs, necessarily, example, literally, better, assuming, called, conclusion\n",
      "\n",
      "Topic  66\n",
      "place, love, order, lose, allow, base, extra, bunch, build, extremely, leads, telling, having, thing, make, wouldnt, people, want, just, win\n",
      "\n",
      "Topic  67\n",
      "states, figure, actually, period, medical, feminism, global, involved, used, exist, massive, wealth, protect, affect, came, somebody, days, going, view, democracy\n",
      "\n",
      "Topic  68\n",
      "evidence, science, earth, theory, possible, lack, assume, studies, false, prove, systems, research, development, factors, case, suggest, doubt, ultimately, says, literally\n",
      "\n",
      "Topic  69\n",
      "form, talking, completely, places, standard, ignore, star, separate, numbers, wars, stupid, thats, planet, just, different, used, force, watch, makes, points\n",
      "\n",
      "Topic  70\n",
      "human, experience, fine, examples, wanted, similar, removed, news, students, speak, ive, open, relationships, meant, democracy, data, standard, conservative, punishment, great\n",
      "\n",
      "Topic  71\n",
      "away, getting, taking, taken, takes, save, uk, multiple, involved, requires, time, spent, short, directly, leave, necessarily, agree, trying, better, unless\n",
      "\n",
      "Topic  72\n",
      "culture, statement, context, cultural, address, response, premise, calling, actively, history, ones, different, inherently, necessarily, true, come, thing, entire, said, problem\n",
      "\n",
      "Topic  73\n",
      "states, choice, water, god, united, competitive, players, level, sports, equal, prevent, smaller, running, levels, large, national, run, far, points, way\n",
      "\n",
      "Topic  74\n",
      "treat, especially, millions, lack, address, generally, minority, victim, local, equally, line, living, idea, prevent, wanted, effect, consequences, quite, allowing, reason\n",
      "\n",
      "Topic  75\n",
      "health, killed, looking, meaning, looks, room, physical, meat, welfare, game, culture, world, act, minimum, effect, rational, increase, treatment, obviously, youre\n",
      "\n",
      "Topic  76\n",
      "able, space, safe, answer, spend, turn, friend, room, solution, clear, week, supposed, actual, close, hours, actually, used, just, pretty, simple\n",
      "\n",
      "Topic  77\n",
      "money, pay, paying, paid, negative, employees, end, class, given, explain, job, force, arent, wages, university, specific, raise, company, create, thats\n",
      "\n",
      "Topic  78\n",
      "similar, effect, big, consequences, literally, defense, characters, works, parent, world, told, deserve, taken, provide, campaign, seriously, inherently, mind, happens, birth\n",
      "\n",
      "Topic  79\n",
      "country, worth, fall, differences, biggest, countries, argue, quite, lead, time, strong, better, reason, learning, makes, people, fact, making, work, like\n",
      "\n",
      "Topic  80\n",
      "career, job, economy, decision, responsible, long, guess, ill, add, line, theory, spending, problems, pretty, popular, likely, option, children, ban, majority\n",
      "\n",
      "Topic  81\n",
      "say, exist, saying, im, word, words, use, different, concept, going, used, simply, fuck, conversation, reason, point, correct, cmv, acceptable, meaning\n",
      "\n",
      "Topic  82\n",
      "human, things, ability, brain, natural, intelligence, nature, scale, affect, evolution, basic, biological, basis, does, like, ways, powerful, simply, think, just\n",
      "\n",
      "Topic  83\n",
      "change, potential, lead, view, future, consequences, results, immoral, past, inherently, far, ways, expect, make, assuming, reading, dont, like, feel, sex\n",
      "\n",
      "Topic  84\n",
      "life, good, bad, moral, thing, stop, try, kill, things, just, killing, ok, like, trying, think, idea, sounds, believe, agree, possible\n",
      "\n",
      "Topic  85\n",
      "just, theyre, youre, going, theres, like, thats, dont, people, im, youve, really, way, things, know, actually, say, lot, thing, killed\n",
      "\n",
      "Topic  86\n",
      "doing, doesnt, message, know, cause, attention, want, people, public, good, culture, help, problem, going, issue, case, benefit, car, need, theyre\n",
      "\n",
      "Topic  87\n",
      "sound, massive, place, gain, second, trade, republican, options, gets, safe, age, useful, wants, calling, terrorism, policy, parent, examples, differences, violence\n",
      "\n",
      "Topic  88\n",
      "based, view, evil, justice, punishment, op, willing, hell, judge, comments, conclusion, reasonable, hold, allowing, different, thats, instance, theres, really, people\n",
      "\n",
      "Topic  89\n",
      "question, number, type, meant, used, include, scientific, designed, mentioned, clearly, comments, compare, allow, different, lot, thats, really, point, way, just\n",
      "\n",
      "Topic  90\n",
      "questions, quite, intelligence, options, welfare, unless, character, minimum, debt, computer, win, mental, studies, didnt, able, field, art, thought, shes, cut\n",
      "\n",
      "Topic  91\n",
      "rule, including, things, prices, peoples, help, arent, spent, classes, forcing, working, afford, points, doubt, premise, face, democracy, drugs, laws, kid\n",
      "\n",
      "Topic  92\n",
      "game, games, play, kids, playing, video, fun, skill, time, watch, waste, win, different, just, prefer, allows, generally, type, example, trying\n",
      "\n",
      "Topic  93\n",
      "told, possibly, minority, hurt, free, help, physical, statement, adult, weapons, points, easy, punishment, religious, day, little, new, economy, evil, democrats\n",
      "\n",
      "Topic  94\n",
      "world, problem, live, people, learn, think, mind, skills, life, resources, important, somebody, course, time, reading, seeing, dont, problems, experience, isnt\n",
      "\n",
      "Topic  95\n",
      "personally, options, responsible, youd, candidates, writing, directly, better, chance, belief, hillary, face, believe, playing, illegal, people, shot, okay, candidate, force\n",
      "\n",
      "Topic  96\n",
      "crime, higher, environment, crimes, rate, rates, compared, generally, commit, lower, damage, criminal, overall, particularly, longer, far, example, incredibly, extremely, rest\n",
      "\n",
      "Topic  97\n",
      "public, line, private, debate, discussion, honestly, allow, agree, isnt, right, bernie, obviously, weapons, main, just, lot, property, arguments, carry, place\n",
      "\n",
      "Topic  98\n",
      "sports, study, legal, hate, result, lot, rates, later, climate, explain, today, nearly, ignore, man, totally, access, particular, crimes, obviously, potential\n",
      "\n",
      "Topic  99\n",
      "baby, people, getting, market, rich, think, american, housing, workers, house, believe, just, average, years, happen, im, old, isnt, prices, money\n",
      "\n",
      "Topic  100\n",
      "basically, post, fine, content, limit, posts, account, practice, saying, taking, limited, doing, like, just, dont, totally, hold, people, lot, reason\n",
      "\n",
      "Topic  101\n",
      "past, critical, scenario, reduce, eventually, worked, lots, rates, little, explain, works, wrong, obvious, court, useful, involved, planet, particular, lot, areas\n",
      "\n",
      "Topic  102\n",
      "country, laws, happening, spend, seriously, fine, takes, impact, eating, financial, living, including, value, property, defense, crimes, low, potential, break, college\n",
      "\n",
      "Topic  103\n",
      "parties, modern, healthy, house, exists, id, career, wasnt, clearly, larger, liberal, federal, ask, eating, land, teach, computer, writing, friends, religions\n",
      "\n",
      "Topic  104\n",
      "moment, easily, youre, potentially, tax, address, creating, systems, smaller, product, lot, gain, love, purpose, politics, say, parts, questions, words, public\n",
      "\n",
      "Topic  105\n",
      "gun, guns, control, dangerous, check, guys, background, defense, carry, weapons, self, national, kill, prevent, buy, mass, reason, killing, happen, criminal\n",
      "\n",
      "Topic  106\n",
      "school, college, education, class, students, student, schools, high, major, university, classes, safety, teach, level, better, getting, taking, require, computer, having\n",
      "\n",
      "Topic  107\n",
      "male, interesting, female, treatment, issues, thing, actually, fact, did, comes, going, makes, really, peoples, having, reason, means, long, make, people\n",
      "\n",
      "Topic  108\n",
      "time, make, just, going, rules, run, bit, really, long, point, later, bad, like, leave, pretty, knew, theyll, decided, gets, figure\n",
      "\n",
      "Topic  109\n",
      "dont, like, know, think, feel, want, good, just, make, really, better, usually, im, look, need, situation, people, thats, lot, feeling\n",
      "\n",
      "Topic  110\n",
      "arent, easily, physical, service, areas, continue, fairly, just, simple, having, parts, doesnt, happens, necessarily, mean, understand, companies, thats, video, standard\n",
      "\n",
      "Topic  111\n",
      "hes, look, similar, probably, said, hand, example, morality, mention, opinions, looking, different, pass, members, head, critical, wouldnt, true, possibly, certainly\n",
      "\n",
      "Topic  112\n",
      "id, happened, lost, say, got, actual, absolutely, bunch, considered, theyll, inflation, civil, emotional, created, op, president, didnt, economy, levels, youll\n",
      "\n",
      "Topic  113\n",
      "deleted, id, incredibly, talk, necessary, topic, personally, good, terms, constitution, playing, persons, teach, gay, real, held, successful, dogs, seeing, influence\n",
      "\n",
      "Topic  114\n",
      "use, people, body, gay, community, risk, mental, death, force, weight, straight, treat, accept, called, needed, having, protect, brain, fact, simply\n",
      "\n",
      "Topic  115\n",
      "average, low, normal, born, income, buy, little, point, instance, think, value, energy, unless, level, imagine, effective, differences, water, limited, build\n",
      "\n",
      "Topic  116\n",
      "ability, long, heres, logical, team, quality, expensive, pretty, rule, racist, male, vast, line, products, power, removed, told, rate, computer, guns\n",
      "\n",
      "Topic  117\n",
      "likely, result, come, sort, way, harm, let, people, despite, situations, just, factor, reason, knowing, say, lot, true, making, think, sexist\n",
      "\n",
      "Topic  118\n",
      "case, majority, opinion, regardless, court, vast, cases, congress, probably, make, likely, group, agree, nearly, second, reason, favor, entirely, particularly, heard\n",
      "\n",
      "Topic  119\n",
      "war, military, europe, fighting, civil, period, world, maintain, time, interested, caused, fight, weapons, countries, far, wars, large, history, western, especially\n",
      "\n",
      "Topic  120\n",
      "american, poor, america, economic, housing, poverty, financial, afford, nations, americans, nation, better, government, far, wealth, history, great, social, help, people\n",
      "\n",
      "Topic  121\n",
      "fair, theres, hours, actively, changed, certain, studies, gets, ai, probably, totally, pain, trump, ignore, specifically, problems, quite, depends, dogs, general\n",
      "\n",
      "Topic  122\n",
      "relationship, doesnt, held, options, bunch, ability, energy, popular, option, gives, basis, mention, half, win, posts, experiences, doubt, supporters, especially, sounds\n",
      "\n",
      "Topic  123\n",
      "absolutely, necessary, market, responsibility, welfare, assumption, known, protect, far, fact, consequences, prices, work, lives, high, need, called, risk, make, use\n",
      "\n",
      "Topic  124\n",
      "free, decisions, definition, experience, thought, argument, assumption, know, using, think, actions, make, im, source, choice, role, good, understanding, second, doesnt\n",
      "\n",
      "Topic  125\n",
      "maybe, isnt, shouldnt, story, like, think, works, actually, character, fair, book, way, really, just, characters, told, deserve, make, look, doesnt\n",
      "\n",
      "Topic  126\n",
      "government, marriage, legal, position, topic, effective, note, raise, support, gay, order, cause, control, argue, idea, issues, exists, groups, opposed, truly\n",
      "\n",
      "Topic  127\n",
      "means, answer, point, equally, reasons, significantly, systems, liberal, death, europe, harder, mental, results, wages, free, welfare, book, tldr, big, yes\n",
      "\n",
      "Topic  128\n",
      "use, building, high, necessary, risk, day, fact, mental, death, called, far, body, accept, force, impact, similar, small, room, require, drug\n",
      "\n",
      "Topic  129\n",
      "countries, country, culture, language, learning, love, worth, fun, better, point, fall, time, making, makes, theyre, money, different, work, ive, personal\n",
      "\n",
      "Topic  130\n",
      "need, using, data, information, use, internet, available, access, ads, security, alcohol, just, explain, disagree, agree, prove, online, known, evidence, actually\n",
      "\n",
      "Topic  131\n",
      "imagine, wanted, thinking, test, bring, list, fight, young, hurt, obvious, consider, far, knowing, living, ways, time, kind, really, youve, important\n",
      "\n",
      "Topic  132\n",
      "birth, character, change, parts, lack, force, ok, civil, assumption, dollars, field, known, enjoy, earth, benefits, female, vs, liberal, science, labor\n",
      "\n",
      "Topic  133\n",
      "rape, process, technology, cases, remember, face, learning, victim, perfect, victims, talk, various, information, point, issues, know, issue, far, time, entirely\n",
      "\n",
      "Topic  134\n",
      "black, families, white, americans, government, american, property, social, america, consider, history, poverty, economic, today, society, wealth, housing, home, important, life\n",
      "\n",
      "Topic  135\n",
      "population, violence, immigrants, immigration, mass, terrorism, violent, people, expect, nearly, cause, legal, killing, issues, influence, isnt, factor, think, murder, probably\n",
      "\n",
      "Topic  136\n",
      "sort, raise, honestly, examples, labor, dogs, demand, technology, caused, cases, deleted, logic, ability, accept, dont, hours, wont, continue, usually, humans\n",
      "\n",
      "Topic  137\n",
      "concept, president, voted, background, systems, mentioned, definition, prevent, lost, guys, ultimately, values, mass, youre, goal, aware, dog, clearly, court, parent\n",
      "\n",
      "Topic  138\n",
      "policy, nuclear, open, citizens, energy, foreign, policies, millions, large, constitution, protect, trade, security, nations, currently, dollars, process, option, president, wants\n",
      "\n",
      "Topic  139\n",
      "understand, like, read, enjoy, purpose, way, just, music, ill, understanding, thought, product, books, exists, write, writing, add, dont, highly, different\n",
      "\n",
      "Topic  140\n",
      "think, makes, takes, experience, reading, people, live, life, seeing, world, mental, mind, fine, important, dont, nature, account, learn, deal, view\n",
      "\n",
      "Topic  141\n",
      "animals, meat, fear, animal, effects, pain, truly, plenty, medical, heard, putting, life, killing, possible, way, live, wrong, dogs, industry, like\n",
      "\n",
      "Topic  142\n",
      "people, think, dont, want, things, like, views, just, really, agree, disagree, arent, isnt, issues, im, way, actually, point, idea, movement\n",
      "\n",
      "Topic  143\n",
      "essentially, instead, energy, compare, room, stay, follow, hurt, population, exists, interested, political, voted, literally, healthcare, politicians, rational, victim, abortion, heres\n",
      "\n",
      "Topic  144\n",
      "work, knowledge, time, need, field, just, climate, dont, doesnt, make, think, point, things, eventually, better, like, able, know, way, working\n",
      "\n",
      "Topic  145\n",
      "power, tax, taxes, current, increase, advantage, status, effectively, politicians, people, simply, makes, having, fact, unfair, long, provide, true, going, federal\n",
      "\n",
      "Topic  146\n",
      "value, left, seen, ive, trade, values, changes, price, demand, allows, true, make, tend, especially, points, personally, action, directly, think, win\n",
      "\n",
      "Topic  147\n",
      "arguments, ignore, required, guns, western, existence, short, result, explain, caused, assuming, ways, wants, citizens, address, cost, set, beliefs, idea, car\n",
      "\n",
      "Topic  148\n",
      "youre, wrong, act, unless, matter, decide, havent, valid, think, opinion, fit, ones, telling, able, want, allows, set, instead, willing, having\n",
      "\n",
      "Topic  149\n",
      "large, police, logic, amendment, maybe, issue, animal, killed, meaning, specific, rights, leads, life, born, dollars, example, problems, question, did, able\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda_model,my_vectorizer.get_feature_names(),20) # We have to look at the topics before hand and then add the labels afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTextRank for graph-based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'da5sh31',\n",
       " 'text': 'I am an organ donor.  I want my organs to go to people who need my organs. I do not want my donation of my organs to get involved in notion of social justice, of \"deserving\" and so on.  The organ I donate goes to someone who is sick, because being sick is a really shitty thing.  It\\'s not _less shitty_ when it happens to an asshole, or even to someone who doesn\\'t want to donate their own organs.  My gift is not contingent.\\n\\nI agree with you that it should not be taken for granted, I believe that it should be wildly promoted and that we should change our systems of becoming an organ donor.  As you note, this is about saving lives.  I believe it to be bad to create a system that implicitly values one life greater than the other, and that is what your proposal does.  It says that you deserve to live because you are an organ donor and you don\\'t because you aren\\'t.\\n\\nAnd...Get your shit together Canada!',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_table = str.maketrans({'\\n': ' ', \"'\": '', '-': '', '/': ''})\n",
    "train_dicts = [{'id': doc['id'], 'text': doc['text'].translate(replacement_table)} for doc in train_docs]\n",
    "test_dicts = [{'id': doc['id'], 'text': doc['text'].translate(replacement_table)} for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12063"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'da5sh31', 'text': 'I am an organ donor.  I want my organs to go to people who need my organs. I do not want my donation of my organs to get involved in notion of social justice, of \"deserving\" and so on.  The organ I donate goes to someone who is sick, because being sick is a really shitty thing.  Its not _less shitty_ when it happens to an asshole, or even to someone who doesnt want to donate their own organs.  My gift is not contingent.  I agree with you that it should not be taken for granted, I believe that it should be wildly promoted and that we should change our systems of becoming an organ donor.  As you note, this is about saving lives.  I believe it to be bad to create a system that implicitly values one life greater than the other, and that is what your proposal does.  It says that you deserve to live because you are an organ donor and you dont because you arent.  And...Get your shit together Canada!'}\n"
     ]
    }
   ],
   "source": [
    "print(train_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "5050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "5300\n",
      "5350\n",
      "5400\n",
      "5450\n",
      "5500\n",
      "5550\n",
      "5600\n",
      "5650\n",
      "5700\n",
      "5750\n",
      "5800\n",
      "5850\n",
      "5900\n",
      "5950\n",
      "6000\n",
      "6050\n",
      "6100\n",
      "6150\n",
      "6200\n",
      "6250\n",
      "6300\n",
      "6350\n",
      "6400\n",
      "6450\n",
      "6500\n",
      "6550\n",
      "6600\n",
      "6650\n",
      "6700\n",
      "6750\n",
      "6800\n",
      "6850\n",
      "6900\n",
      "6950\n",
      "7000\n",
      "7050\n",
      "7100\n",
      "7150\n",
      "7200\n",
      "7250\n",
      "7300\n",
      "7350\n",
      "7400\n",
      "7450\n",
      "7500\n",
      "7550\n",
      "7600\n",
      "7650\n",
      "7700\n",
      "7750\n",
      "7800\n",
      "7850\n",
      "7900\n",
      "7950\n",
      "8000\n",
      "8050\n",
      "8100\n",
      "8150\n",
      "8200\n",
      "8250\n",
      "8300\n",
      "8350\n",
      "8400\n",
      "8450\n",
      "8500\n",
      "8550\n",
      "8600\n",
      "8650\n",
      "8700\n",
      "8750\n",
      "8800\n",
      "8850\n",
      "8900\n",
      "8950\n",
      "9000\n",
      "9050\n",
      "9100\n",
      "9150\n",
      "9200\n",
      "9250\n",
      "9300\n",
      "9350\n",
      "9400\n",
      "9450\n",
      "9500\n",
      "9550\n",
      "9600\n",
      "9650\n",
      "9700\n",
      "9750\n",
      "9800\n",
      "9850\n",
      "9900\n",
      "9950\n",
      "10000\n",
      "10050\n",
      "10100\n",
      "10150\n",
      "10200\n",
      "10250\n",
      "10300\n",
      "10350\n",
      "10400\n",
      "10450\n",
      "10500\n",
      "10550\n",
      "10600\n",
      "10650\n",
      "10700\n",
      "10750\n",
      "10800\n",
      "10850\n",
      "10900\n",
      "10950\n",
      "11000\n",
      "11050\n"
     ]
    }
   ],
   "source": [
    "import pytextrank\n",
    "import sys\n",
    "\n",
    "path_stage0 = 'stage0.json'\n",
    "path_stage1 = 'stage1.json'\n",
    "path_stage2 = 'stage2.json'\n",
    "path_stage3 = 'stage3.json'\n",
    "\n",
    "#did 0-1000\n",
    "\n",
    "i=0\n",
    "for i, doc_dict in enumerate(train_dicts[1000::]):\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    with open(path_stage0, 'w') as f:\n",
    "        json.dump(doc_dict, f)\n",
    "    # Stage 1    \n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(path_stage0)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "            # print(pytextrank.pretty_print(graf))\n",
    "    # Stage 2\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "    with open(path_stage2, 'w') as f:\n",
    "        for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(rl._asdict()))\n",
    "            # to view output in this notebook\n",
    "            # print(pytextrank.pretty_print(rl))\n",
    "    # Stage 3\n",
    "    kernel = pytextrank.rank_kernel(path_stage2)\n",
    "    with open(path_stage3, 'w') as f:\n",
    "        for s in pytextrank.top_sentences(kernel, path_stage1):\n",
    "            f.write(pytextrank.pretty_print(s._asdict()))\n",
    "            f.write(\"\\n\")\n",
    "            # to view output in this notebook\n",
    "            # print(pytextrank.pretty_print(s._asdict()))\n",
    "    # Stage 4\n",
    "    phrase_list = list(set([p for p in pytextrank.limit_keyphrases(path_stage2, phrase_limit=15)]))\n",
    "    phrases = \", \".join(phrase_list)\n",
    "    \n",
    "    sent_iter = sorted(pytextrank.limit_sentences(path_stage3, word_limit=150), key=lambda x: x[1])\n",
    "    s = []\n",
    "\n",
    "    for sent_text, idx in sent_iter:\n",
    "        s.append(pytextrank.make_sentence(sent_text))\n",
    "\n",
    "    graf_text = \" \".join(s)\n",
    "    \n",
    "    tl_comments_collection.update_one({f'{doctype}_id': {'$eq': doc_dict['id']}},{'$set': {'key_phrases': phrase_list}})\n",
    "    \n",
    "    #print(\"**excerpts:** %s\\n\\n**keywords:** %s\" % (graf_text, phrases), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrase_gen = tl_comments_collection.find({'key_phrases': {\"$exists\": True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrases_list = [comment['key_phrases'] for comment in key_phrase_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46022\n"
     ]
    }
   ],
   "source": [
    "flat_key_phrases = [item for sublist in key_phrases_list for item in sublist]\n",
    "key_phrases_list = list(set(flat_key_phrases))\n",
    "print(len(key_phrases_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_key_phrases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_array = np.array(key_phrases_list)\n",
    "key_phrases_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vectorizer = CountVectorizer(max_df=0.9, min_df=5,\n",
    "                                    max_features=20000,\n",
    "                                    vocabulary = phrase_array,\n",
    "                                    binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "textranked_train_texts = binary_vectorizer.fit_transform(cleaned_train_texts)\n",
    "textranked_test_texts = binary_vectorizer.transform(cleaned_test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the type of topic modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_train_texts = textranked_train_texts\n",
    "reduced_test_texts = textranked_test_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling undeltad observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(class_weight='balanced', random_state=rand_state)\n",
    "svc_model.fit(reduced_train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2630   14]\n",
      " [ 362    8]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = svc_model.predict(reduced_test_texts)\n",
    "conf_mat = confusion_matrix(test_labels, predicted_labels)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy is 0.8752488387524884\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy is {}'.format(svc_model.score(reduced_test_texts, test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model = XGBClassifier(scale_pos_weight=7)\n",
    "xg_model.fit(reduced_train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mean accuracy is 0.7223742021056122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleanor/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print('train set mean accuracy is {}'.format(xg_model.score(reduced_train_texts, train_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy is 0.6718646317186463\n",
      "[[1841  803]\n",
      " [ 186  184]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleanor/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/eleanor/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy is {}'.format(xg_model.score(reduced_test_texts, test_labels)))\n",
    "predicted_labels = xg_model.predict(reduced_test_texts)\n",
    "conf_mat = confusion_matrix(test_labels, predicted_labels)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbscan_model = DBSCAN(eps=0.5, min_samples=5, metric=euclidean, metric_params=None, algorithm=auto, leaf_size=30, p=None, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=rand_state, class_weight='balanced')\n",
    "logreg.fit(reduced_train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_labels = logreg.predict(reduced_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy is 0.6766313082610094\n",
      "[[1925  795]\n",
      " [ 211  180]]\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy is {}'.format(logreg.score(reduced_test_texts, test_labels)))\n",
    "conf_mat = confusion_matrix(test_labels, predicted_test_labels)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
